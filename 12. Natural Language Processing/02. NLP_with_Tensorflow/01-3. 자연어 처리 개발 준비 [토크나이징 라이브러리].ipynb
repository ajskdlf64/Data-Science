{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자연어 토크나이징 도구\n",
    "자연어 처리를 위해서는 우선 텍스트에 대한 정보를 단위별로 나누는 것이 일반적이다. 예를 들어 영화 리뷰 내용을 예측한다고 하면 한 문장을 단어 단위로 쪼개서 분석할 수 있다. 이처럼 예측해야 할 입력 정보를 하나의 특정 기본 던위로 자르는 것을 토크나이징이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영어 토크나이징 라이브러리\n",
    "NLTK(Natural Language Toolkit)와 Spacy가 토크나이징에 많이 쓰이는 대표적인 라이브러리다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "NLTK는 파이썬에서 영어 텍스트 전처리 작업을 하는데 많이 쓰이는 라이브러리다. 이 라이브러리는 50여 개가 넘는 말뭉치 리소스를 활용해 영어 텍스트를 분석할 수 있게 제공한다. 직관적으로 함수를 쉽게 사용할 수 있게 구성되어 있어 텍스트 전처리를 할 수있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NLTK 라이브러리 호출 및 말뭉치 다운\n",
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토크나이징이란 텍스트에 대해 특정 기준 단위로 문장을 나눈 것을 의미한다. 예를 들면, 문장을 단어 기준으로 나누거나 전체 글을 문장 단위로 나누는 것들이 토크나이징에 해당한다.\n",
    "\n",
    "파이썬에서 간단하게 문자열에 대해 split 함수를 사용해서 나눌 수도 있지만 라이브러리를 사용하면 훨씬 더 간편하고 효과적으로 토크나이징할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어 단위 토크나이징\n",
    "영어 텍스트를 정의한 후 word_tokenize 함수에 적용하면 다음과 같이 구분된 리스트를 받을 수 있다.\n",
    "\n",
    "결과를 보면, 모두 단어로 구분되어 있고, 특수 문자의 경우 따로 구분되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'computer', 'science', ',', 'information', 'engineering', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "sentence = \"Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analze large amounts of natural language data.\"\n",
    "print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장 단위 토크나이징\n",
    "결과를 보면 위의 텍스트가 두 개의 문장으로 나눠진 리스트로 나오는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analze large amounts of natural language data.', 'Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "paragraph = \"Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analze large amounts of natural language data. Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.\"\n",
    "print(sent_tokenize(paragraph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy\n",
    "Spacy는 NLTK와 같은 오픈소스 라이브러리다. 주로 교육, 연구 목적이 아닌 상업용 목적으로 만들어졌다는 점에서 NLTK와 다른 목적으로 만들어진 라이브러리다. Spacy는 현재 영어를 포함한 8개 국어에 대한 자연어 전처리 모듈을 제공하고, 빠른 속도로 전처리할 수 있다. 또한 쉽게 설치하고 원하는 언어에 대한 전처리를 한 번에 해결할 수 있다는 장점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy 토크나이징\n",
    "NLTK는 단어와 문장 단위의 토크나이징이 구분되어 있지만 Spacy에서는 모두 동일한 모듈을 사용한다.\n",
    "\n",
    "1. 먼저 spacy('en')을 통해 토크나이징할 객체를 생성해서 nlp 변수에 할당한다.\n",
    "2. 토크나이징할 텍스트를 sentence에 할당해서 nlp(sentence)를 실행해 nlp 객체에 대해 호출한다.\n",
    "3. 그러고 나면, 텍스트에 대해 구문 분석 객체를 doc 변수에 할당한다.\n",
    "4. 이 doc 객체를 가지고 입력한 텍스트에 대한 토크나이징을 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 토크나이징\n",
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'computer', 'science', ',', 'information', 'engineering', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.', 'Challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'speech', 'recognition', ',', 'natural', 'language', 'understanding', ',', 'and', 'natural', 'language', 'generation', '.']\n",
      "\n",
      "문장 토크나이징\n",
      "['Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analze large amounts of natural language data.', 'Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "sentence = \"Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analze large amounts of natural language data. Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.\"\n",
    "\n",
    "doc = nlp(sentence)\n",
    "\n",
    "word_tokenized_sentence = [token.text for token in doc]\n",
    "sentence_tokenized_list = [sent.text for sent in doc.sents]\n",
    "\n",
    "print(\"단어 토크나이징\")\n",
    "print(word_tokenized_sentence)\n",
    "print(\"\")\n",
    "print(\"문장 토크나이징\")\n",
    "print(sentence_tokenized_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토크나이징할 때는 doc 객체를 활용해 [token.text for token in doc]과 같이 리스트 컴프리헨션을 활용하면 간단하게 토크나이징 결과를 확인할 수 있다.\n",
    "\n",
    "리스트 컴프리헨션은 파이썬에서 제공하는 기능으로 한 리스트의 모든 원소 각각에 어떤 함수를 적용한 후, 그 반환값을 원소로 가지는 다른 리스트를 쉽게 만들 수 있다.\n",
    "\n",
    "doc 객체에 대해 반복문을 사용하면 단어를 기준으로 토큰이 나오고 doc.sents 값에 대해 반복문을 사용하면 문장을 기준으로 토크나이징된다.\n",
    "\n",
    "NLTK는 함수를 통해 토크나이징을 했지만 Spacy는 객체를 생성하는 방식으로 구현되어 있다. 이처럼 객체를 생성하는 이유는 이 객체를 통해 단순히 토크나이징뿐만 아니라 갖가지 다른 자연어 전처리 기능을 제공할 수 있기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한글 토크나이징 라이브러리\n",
    "KoNLPy는 형태소 분석으로 형태소 단위의 토크나이징을 가능하게 할뿐만 아니라 구문 분석을 가능하게 해서 언어 분석을 하는데 유용한 도구다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KoNLPy\n",
    "이 라이브러리는 한글 자연어 처리를 쉽고 간결하게 처리할 수 있도록 만들어진 오픈소스 라이브러리다. \n",
    "\n",
    "KoNLPy의 경우 기존의 자바로 쓰여진 형태소 분석기를 사용하기 때문에 윈도우에서 KoNLPy를 설치하기 위해서는 1.7 이상의 자바(Java)가 설치되어 있어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 단위 토크나이징\n",
    "한글의 경우 형태소 단위의 토크나이징이 필요할 때가 있다. KoNLPy에서는 여러 형태소 분석기를 제공하며, 각 형태소 분석기별로 분석한 결과는 다를 수 있다. 각 형태소 분석기별로 분석한 결과는 다를 수 있다. 각 형태소 분석기는 클래스 형태로 되어 있고, 이를 객체로 생성한 후 메서드를 호출해서 토크나이징할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석 및 품사 태깅\n",
    "형태소 분석을 설명하기 전에 먼저 형태소가 무엇인지 알아야한다. 형태소란 의미를 가지는 가장 작은 단위로서 더 쪼개지면 의미를 상실하는 것들을 말한다. 따라서 형태소 분석이란 의미를 가지는 단위를 기준으로 문장을 살펴보는 것을 말한다.\n",
    "\n",
    "#### KoNLPy에 포함된 형태소 분석기\n",
    " - Hannanum\n",
    " - Kkma\n",
    " - Komoran\n",
    " - Mecab\n",
    " - Okt(Twittter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석기 Okt\n",
    " - okt.morphs() : 텍스트를 형태소 단위로 나눈다.\n",
    " - okt.nouns() : 텍스트에서 명사만 뽑아낸다.\n",
    " - okt.phrases() : 텍스트에서 어절을 뽑아낸다.\n",
    " - okt.pos() : 각 품사를 태깅한다.\n",
    " \n",
    "- 품사를 태깅한다는 말은 주어진 택스트를 형태소 단위로 나누고, 나눠진 각 형태소를 그에 해당하는 ㅜㅁ사와 함께 리스트화 하는 것을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태소 단위로 추출 : ['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '해야지', 'ㅎㅎㅎ']\n",
      "형태소 단위로 나눈 후 어간을 추출 : ['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '하다', 'ㅎㅎㅎ']\n",
      "\n",
      "명사만 추출 : ['한글', '자연어', '처리', '이제']\n",
      "\n",
      "어절만 추출 : ['한글', '한글 자연어', '한글 자연어 처리', '이제', '자연어', '처리']\n",
      "\n",
      "품사 태깅 : [('한글', 'Noun'), ('자연어', 'Noun'), ('처리', 'Noun'), ('는', 'Josa'), ('재밌다', 'Adjective'), ('이제', 'Noun'), ('부터', 'Josa'), ('열심히', 'Adverb'), ('해야지', 'Verb'), ('ㅎㅎㅎ', 'KoreanParticle')]\n",
      "\n",
      "형태소와 품사를 붙여서 리스트화 : ['한글/Noun', '자연어/Noun', '처리/Noun', '는/Josa', '재밌다/Adjective', '이제/Noun', '부터/Josa', '열심히/Adverb', '해야지/Verb', 'ㅎㅎㅎ/KoreanParticle']\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 호출\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# okt 객체 생성\n",
    "okt = Okt()\n",
    "\n",
    "# 텍스트 생성\n",
    "text = \"한글 자연어 처리는 재밌다 이제부터 열심히 해야지ㅎㅎㅎ\"\n",
    "\n",
    "# 형태소 단위로 추출\n",
    "print(\"형태소 단위로 추출 :\", okt.morphs(text))\n",
    "\n",
    "# 형태소 단위로 나눈 후 어간을 추출\n",
    "# \"해야지\"의 어간인 \"하다\"로 추출된다.\n",
    "print(\"형태소 단위로 나눈 후 어간을 추출 :\", okt.morphs(text, stem=True))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# 명사만 추출\n",
    "print(\"명사만 추출 :\", okt.nouns(text))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# 어절만 추출\n",
    "print(\"어절만 추출 :\", okt.phrases(text))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# 품사 태깅\n",
    "print(\"품사 태깅 :\", okt.pos(text))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# 형태소와 품사를 붙여서 리스트화\n",
    "print(\"형태소와 품사를 붙여서 리스트화 :\", okt.pos(text, join=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KoNLPy 데이터\n",
    "이 라이브러리 안에는 한글 자연어 처리에 활용할 수 있는 한글 데이터를 포함하고 있다.\n",
    "\n",
    "#### kolaw\n",
    " - 한글 법률 말뭉치, 'constitiuion.txt'로 저장되어 있다.\n",
    " \n",
    "#### kobill\n",
    " - 대한민국 국회 의안 말뭉치, 각 id 값을 가지는 의안으로 구성되어 있고 파일은 '1809890.txt'부터 '1809899.txt'까지 구성되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "from konlpy.corpus import kolaw\n",
    "from konlpy.corpus import kobill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국헌법\n",
      "\n",
      "유구한 역사와 전통에 빛나는 우리 대한국민은 3·1운동으로 건립된 대한민국임시정부의 법통과 불의에 항거한 4·19민주이념을 계승하고, 조국의 민주개혁과 평화적 통일의 사명에 입각하여 정의·인도와 동포애로써 민족의 단결을 공고히 하고, 모든 사회적 폐습과 불의를 타파하며, 자율과 조화를 바탕으로 자유민주적 기본질서를 더욱 확고히 하여 정치·경제·사회·문화의 모든 영역에 있어서 각인의 기회를 균등히 하고, 능력을 최고도로 발휘하게 하며, 자유와 권리에 따르는 책임과 의무를 완수하게 하여, 안으로는 국민생활의 균등한 향상을 기하고 밖으로는 항구적인 세계평화와 인류공영에 이바지함으로써 우리들과 우리들의 자손의 안전과 자유와 행복을 영원히 확보할 것을 다짐하면서 1948년 7월 12일에 제정되고 8차에 걸쳐 개정된 헌법을 이제 국회의 의결을 거쳐 국민투표에 의하여 개정한다.\n",
      "\n",
      "       제1장 총강\n",
      "  제1조 ① 대한민국은 민주공화국이다.\n",
      "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.\n",
      "  제2조 ① 대한민국의 국민이 되는 요건은 법률로 정한다.\n",
      "②국가는 법률이 정하는 바에 의하여 재외국민을 보호할 의무를 진다.\n",
      "  제3조 대한민국의 영토는 한반도와 그 부속도서로 한다.\n",
      "  제4조 대한민국은 통일을 지향하며, 자유민주적 기본질서에 입각한 평화적 통일 정책을 수립하고 이를 추진한다.\n",
      "  제5조 ① 대한민국은 국제평화의 유지에 노력하고 침략적 전쟁을 부인한다.\n",
      "②국군은 국가의 안전보장과 국토방위의 신성한 의무를 수행함을 사명으로 하며, 그 정치적 중립성은 준수된다.\n",
      "  제6조 ① 헌법에 의하여 체결·공포된 조약과 일반적으로 승인된 국제법규는 국내법과 같은 효력을 가진다.\n",
      "②외국인은 국제법과 조약이 정하는 바에 의하여 그 지위가 보장된다.\n",
      "  제7조 ① 공무원은 국민전체에 대한 봉사자이며, 국민에 대하여 책임을 진다.\n",
      "②공무원의 신분과 정치적 중립성은 법률이 정하는 바에 의하여 보장된다.\n",
      "  제8조 ① 정당의 설립은 자유이며, 복수정당제\n"
     ]
    }
   ],
   "source": [
    "# 한글 법률 말뭉치\n",
    "print(kolaw.open(\"constitution.txt\").read()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지방공무원법 일부개정법률안\n",
      "\n",
      "(정의화의원 대표발의 )\n",
      "\n",
      " 의 안\n",
      " 번 호\n",
      "\n",
      "9890\n",
      "\n",
      "발의연월일 : 2010.  11.  12.  \n",
      "\n",
      "발  의  자 : 정의화․이명수․김을동 \n",
      "\n",
      "이\n"
     ]
    }
   ],
   "source": [
    "# 국회 의안 말뭉치\n",
    "print(kobill.open(\"1809890.txt\").read()[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
