{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 유사도 (Text Similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이 노래 누가 만들었어?\n",
    "#### 지금 나오는 노래의 작곡가가 누구야?\n",
    "\n",
    "위의 두 문장은 똑같은 의미이지만 인공지는 스피커에게는 단순하게 다른 문장으로 인식될 것이다. 따라서 각기 다른 대답을 만들어야 하는데, 좀 더 효율성을 위해 비슷한 의미를 가진 문장에 대해서는 같은 대답을 준비할 수 있을 것이다. 이 때 문장이 유사한지 측정해야 하며, 텍스트 유사도 측정 방법을 사용하면 된다.\n",
    "\n",
    "일반적으로 유사도를 측정하기 위해 정량화하는 방법에는 여러 가지가 있다. 단순히 같은 단어의 개수를 사용해서 유사도를 판단하는 방법, 형태소로 나누어 형태소를 비교하는 방법, 자소 단위로 나누어 단어를 비교하는 방법 등 다양한 방법이 있다.\n",
    "\n",
    "그 중에서 딥러닝을 기반으로 텍스트 유사도를 측정하는 방식은 단어, 형태소, 유사도의 종류에 상관 없이 텍스트를 벡터화한 후 벡터화된 각 문장간의 유사도를 측정하는 방식이다.\n",
    "\n",
    "이 때 자주 쓰이는 유사도 측정 방법은 4가지가 있으며 다음과 같다.\n",
    " - 자카드 유사도\n",
    " - 유클리디언 유사도\n",
    " - 맨하탄 유사도\n",
    " - 코사인 유사도\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유사도 측정을 위한 예제 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 휴일인 오늘도 서쪽을 중심으로 폭염이 이어졌는데요, 내일은 반가운 비 소식이 있습니다.\n",
    "\n",
    " - 폭염을 피해서 휴일에 놀러왔다가 갑작스런 비로 인해 망연자실하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF를 활용한 단어 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'갑작스런': 1.4054651081081644, '내일': 1.4054651081081644, '놀러왔다가': 1.4054651081081644, '망연자실': 1.4054651081081644, '반가운': 1.4054651081081644, '서쪽': 1.4054651081081644, '소식': 1.4054651081081644, '오늘': 1.4054651081081644, '으로': 1.4054651081081644, '이어졌는데요': 1.4054651081081644, '인해': 1.4054651081081644, '있습니다': 1.0, '중심': 1.4054651081081644, '폭염': 1.0, '피해서': 1.4054651081081644, '하고': 1.4054651081081644, '휴일': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 생성\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 문장 생성\n",
    "sent = (\"휴일 인 오늘 도 서쪽 을 중심 으로 폭염 이 이어졌는데요, 내일 은 반가운 비 소식 이 있습니다.\", \"폭염 을 피해서 휴일 에 놀러왔다가 갑작스런 비 로 인해 망연자실 하고 있습니다.\")\n",
    "\n",
    "# 문장 단어 벡터화\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sent)\n",
    "\n",
    "idf = tfidf_vectorizer.idf_\n",
    "\n",
    "# 각 수치에 대한 값 시각화\n",
    "print(dict(zip(tfidf_vectorizer.get_feature_names(),idf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자카트 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자카드 유사도(Jaccard Similarity), 또는 자카드 지수는 두 문장을 각각 단어의 집합으로 만든 뒤 두 집합을 통해 유사도를 측정하는 방식이다. 유사도를 측정하는 방법은 두 집합의 교집합인 공통된 단어의 개수를 두 집합의 합집합, 즉 전체 단어의 수로 나누면 된다. 결과값은 0~1 사이의 값이 나오고, 1에 가까울수록 유사도가 높다는 의미다.\n",
    "\n",
    " - A,B : 문장\n",
    " - token : 각 단어\n",
    " \n",
    "$ J(A,B) = {|A \\cap B| \\over |A \\cup B|} = {|token \\, in \\, A \\, \\cap \\, token \\, in \\, B| \\over |token \\, in \\, A \\, \\cup \\, token \\, in  \\, B|}$\n",
    "\n",
    "위의 문장에서 A 문장은 17개, B 문장은 13개, 이고 공통으로 들어간 단어는 6개이다. 따라서 두 문장의 자카드 유사도는 $J(A,B) = {6 \\over 6 + 11 + 13} = {6 \\over 24} = 0.25$ 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코사인 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코사인 유사도는 두 개의 벡터값에서 코사인 각도를 구하는 방법이다. 코사인 유사도 값은 -1과 1 사이의 값을 가지고 1에 가까울수록 유사하다는 것을 의미한다. 코사인 유사도는 유사도를 계산할 때 가장 널리 쓰이는 방법 중 하나이다. 다른 유사도 접근법에 비해 일반적으로 성능이 좋은데, 이는 단순히 좌표 상의 거리를 구하는 다른 유사도 측정 방법에 비해 코사인 유사도는 말 그대로 두 벡터 간의 각도를 구하는 것이기 때문에 방향성의 개념이 더해진다. 두 문장이 유사하다면 같은 방향으로 가리킬 것이고, 유사하지 않을수록 직교로 표현될 것이다.\n",
    "\n",
    "#### 코사인 유사도 공식\n",
    "$cos(\\theta) = {\\vec a \\cdot \\vec b \\over ||\\vec a||\\cdot||\\vec b||}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17952266]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유클리디언 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유클리디언 유사도는 가장 기본적인 거리를 측정하는 유사도 공식이며, 공식은 다음과 같다.\n",
    "\n",
    "#### 유클리디언 유사도 공식\n",
    "$d(x,y) = \\sqrt{(x_1-y_1)^2+(x_2-y_2)^2+\\cdot \\cdot \\cdot +(x_n-y_n)^2}$\n",
    "\n",
    "여기서 구하는 유클리디언 거리(Euclidean Distance)는 L2(L2-Distance)라고 불리며, n차원 공간에서 두 점 사이의 최단 거리를 구하는 접근 법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.28099753]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "euclidean_distances(tfidf_matrix[0:1], tfidf_matrix[1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유클리디안 거리는 단순히 두 점 사이의 거릴 뜻하기 때문에 값에 제한이 없다. 따라서 크기는 점점 커질 수 있다. 따라서 0~1 사이의 값을 갖도록 만들어 주어야 비교가 가능하다.\n",
    "\n",
    "방법은 앞서 문장을 벡터화했었는데, 이 벡터를 일반화(Normalize)한 후 다시 유클리디언 유사도를 측정하면 0과 1사이의 값을 갖게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20491229]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1 정규화\n",
    "# 각 벡터 안의 요소값을 모두 더한 것이 크기가 1이 되도록 벡터들의 크기를 조절\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def l1_normalize(v) : \n",
    "    norm = np.sum(v)\n",
    "    return v / norm\n",
    "\n",
    "tfidf_norm_l1 = l1_normalize(tfidf_matrix)\n",
    "euclidean_distances(tfidf_norm_l1[0:1], tfidf_norm_l1[1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 맨하탄 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "맨하탄 유사도(Manhattan Similarity)는 맨하탄 거리를 이용해 유사도를 측정하는 방법이다. 맨하탄 거리란 사각형 격자로 이루어진 지도에도 출발범에서 도착점까지를 가로지르지 않고 갈 수 있는 최단 거리를 구하는 공식이다. 유클리디언 거리를 L2 거리라고 부르는 반면, 맨하탄 거리는 L1 거리라고 부른다.\n",
    "\n",
    "#### 맨하탄 유사도 공식\n",
    "$MaDistnace = \\sum_{i=1}^N |a_i-b_i|\t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77865927]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "manhattan_distances(tfidf_norm_l1[0:1], tfidf_norm_l1[1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 유사도로 측정하느냐에 따라 4가지 유사도 측정 방법의 값은 모두 다르게 나온다. 따라서 분석 목적에 맞는 유사도 측정 방법을 고르는 것이 매우 중요하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
